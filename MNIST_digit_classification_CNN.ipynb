{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJ8A/x1bdQLwdX0mo1ZvPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SakshiKasture/MNIST_digit_classification/blob/main/MNIST_digit_classification_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AjQo4CaG17te"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Preprocess data: Reshape to 28x28 images with 1 channel (grayscale)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "LMtA-kz92Y-Y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to range 0-1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "65dudJie2bfE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "9r0qfPti2ePQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional layer with 32 filters, kernel size 3x3, activation function ReLU\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))"
      ],
      "metadata": {
        "id": "WY7uQHVY2oYN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling layer, takes max value from 2x2 grid and helps to downsample\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ],
      "metadata": {
        "id": "JU3h8LJd2t4k"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional layer with 64 filters\n",
        "'''multiple convolution layers are needed as they help detect diff features. Adding more convolution layers\n",
        "allows the model to detect more complex features at different levels. For example, the first layer detects basic features\n",
        " like edges, while deeper layers may detect more complex structures like shapes or objects.\n",
        " Pooling layers reduce the spatial size of the image after each convolution, helping the network become\n",
        " more computationally efficient, reduce overfitting, and retain important features.\n",
        "  With multiple pooling layers, we gradually downsample the image, allowing the network to focus on high-level features while keeping the computation manageable.'''\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "# Pooling layer\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ],
      "metadata": {
        "id": "OJFmMz6A3E4d"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the 2D data to 1D\n",
        "''' To connect the learned features to a fully connected layer (Dense layer), the 2D data must be flattened into a 1D vector.in CNNs,\n",
        "the output of convolutional and pooling layers needs flattening to connect to the fully connected (dense) layers, whereas in FNNs,\n",
        "the input needs flattening to fit into the first layer.'''\n",
        "model.add(layers.Flatten())"
      ],
      "metadata": {
        "id": "wOZay-_n3UwF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected layer\n",
        "'''This adds a Dense (fully connected) layer with 64 neurons. It uses the ReLU activation function, which helps the model learn non-linear\n",
        "relationships and introduces sparsity by activating only some neurons.'''\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "'''This adds another Dense layer with 10 neurons (one for each class, i.e., the digits 0-9). The softmax activation function\n",
        "converts the output into a probability distribution, where each neuron represents the probability of the input image belonging to a particular class.\n",
        "The first line is a fully connected layer to process learned features.\n",
        "The second line is the output layer, giving probabilities for each class.'''\n",
        "# Output layer with 10 units (one for each digit)\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "dgykFRS-3tDf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8dtScHw3-2t",
        "outputId": "5cde1d44-2cf9-4607-b203-23af0870e34a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 143ms/step - accuracy: 0.8797 - loss: 0.3981 - val_accuracy: 0.9842 - val_loss: 0.0494\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 143ms/step - accuracy: 0.9844 - loss: 0.0513 - val_accuracy: 0.9862 - val_loss: 0.0446\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 145ms/step - accuracy: 0.9903 - loss: 0.0311 - val_accuracy: 0.9907 - val_loss: 0.0291\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 144ms/step - accuracy: 0.9929 - loss: 0.0231 - val_accuracy: 0.9897 - val_loss: 0.0328\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 142ms/step - accuracy: 0.9945 - loss: 0.0180 - val_accuracy: 0.9894 - val_loss: 0.0356\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e865e794df0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYG1AjVp4EKs",
        "outputId": "b3dcfe2d-11e8-401b-e0e8-7b1255462883"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9860 - loss: 0.0442\n",
            "Test accuracy: 0.989799976348877\n"
          ]
        }
      ]
    }
  ]
}